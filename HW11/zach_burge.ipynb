{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set avg loss: 23081.22833251953 Accuracy: tensor(0.0587)\n",
      "Epoch: 1\n",
      "Training set accuracy: 0.0 %\t Training set loss: 2.3169023990631104\n",
      "Epoch: 1\n",
      "Training set accuracy: 40.0 %\t Training set loss: 0.7304441928863525\n",
      "Epoch: 1\n",
      "Training set accuracy: 80.0 %\t Training set loss: 0.360426664352417\n",
      "Validation set accuracy: 0.0 %\t Validation set loss: 0.26729241013526917\n",
      "Test set avg loss: 1339.4778796434402 Accuracy: tensor(0.9584)\n",
      "Epoch: 2\n",
      "Training set accuracy: 0.0 %\t Training set loss: 0.3400309383869171\n",
      "Epoch: 2\n",
      "Training set accuracy: 40.0 %\t Training set loss: 0.3808347284793854\n",
      "Epoch: 2\n",
      "Training set accuracy: 80.0 %\t Training set loss: 0.32410675287246704\n",
      "Validation set accuracy: 0.0 %\t Validation set loss: 0.23494602739810944\n",
      "Test set avg loss: 938.762925311923 Accuracy: tensor(0.9704)\n",
      "Epoch: 3\n",
      "Training set accuracy: 0.0 %\t Training set loss: 0.21838083863258362\n",
      "Epoch: 3\n",
      "Training set accuracy: 40.0 %\t Training set loss: 0.3207089304924011\n",
      "Epoch: 3\n",
      "Training set accuracy: 80.0 %\t Training set loss: 0.2056093066930771\n",
      "Validation set accuracy: 0.0 %\t Validation set loss: 0.18015770614147186\n",
      "Test set avg loss: 736.501158233732 Accuracy: tensor(0.9767)\n",
      "Epoch: 4\n",
      "Training set accuracy: 0.0 %\t Training set loss: 0.19227443635463715\n",
      "Epoch: 4\n",
      "Training set accuracy: 40.0 %\t Training set loss: 0.08276019245386124\n",
      "Epoch: 4\n",
      "Training set accuracy: 80.0 %\t Training set loss: 0.36720865964889526\n",
      "Validation set accuracy: 0.0 %\t Validation set loss: 0.20033222436904907\n",
      "Test set avg loss: 633.9651062712073 Accuracy: tensor(0.9811)\n",
      "Epoch: 5\n",
      "Training set accuracy: 0.0 %\t Training set loss: 0.14314782619476318\n",
      "Epoch: 5\n",
      "Training set accuracy: 40.0 %\t Training set loss: 0.3888203799724579\n",
      "Epoch: 5\n",
      "Training set accuracy: 80.0 %\t Training set loss: 0.10016399621963501\n",
      "Validation set accuracy: 0.0 %\t Validation set loss: 0.12614428997039795\n",
      "Test set avg loss: 597.8683952819556 Accuracy: tensor(0.9816)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "\n",
    "train = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "train_subset, val_subset = torch.utils.data.random_split(train, [50000, 10000], generator=torch.Generator().manual_seed(1))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_subset, shuffle=True, batch_size=100)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_subset, shuffle=True, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, shuffle=False, batch_size=100)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.l2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.l2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.l1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.l2_drop(self.l2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "nn = Net()\n",
    "optimizer = optim.Adam(nn.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch):\n",
    "  nn.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = nn(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % 200 == 0:\n",
    "      print(\"Epoch:\", epoch)\n",
    "      print(\"Training set accuracy:\", ((batch_idx * len(data))/len(train_loader.dataset)*100), \"%\\t\", \"Training set loss:\", loss.item())\n",
    "\n",
    "def validate():\n",
    "    nn.train()\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = nn(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print()\n",
    "            print(\"Validation set accuracy:\", ((batch_idx * len(data))/len(val_loader.dataset)*100), \"%\\t\", \"Validation set loss:\", loss.item())\n",
    "            print()\n",
    "\n",
    "def test():\n",
    "  nn.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = nn(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum() \n",
    "  print(\"Test set avg loss:\", test_loss, \"Accuracy:\", correct/len(test_loader.dataset))\n",
    "  print()\n",
    "\n",
    "test()\n",
    "for epoch in range(1, 5 + 1):\n",
    "  train(epoch)\n",
    "  validate()\n",
    "  test()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
